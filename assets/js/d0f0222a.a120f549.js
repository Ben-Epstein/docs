"use strict";(self.webpackChunkflojoy_doc=self.webpackChunkflojoy_doc||[]).push([[1706],{62605:(e,n,t)=>{t.d(n,{Z:()=>h});var a=t(67294),l=t(74866),r=t(85162),i=t(11570),o=t(32871),d=t(83599);t(99869);const c=(0,a.memo)((e=>{let{data:n}=e;return a.createElement(a.Fragment,null,a.createElement(i.HH,{type:"target",position:i.Ly.Left,style:{background:"#555"}}),a.createElement("div",null,a.createElement("strong",null,n.label)),a.createElement(i.HH,{type:"source",position:i.Ly.Right,id:"b"}))}));var s=t(33140),E=t(73091),m=t(2029),p=t(76887),u=t(49188),T=t(92949);const f={default:c},C={tickLabels:{fontSize:8,fill:"#BCC2C4"},label:{fontSize:8,fill:"#BCC2C4"}};function h(e){let{children:n,data:t,GLink:c}=e;const{colorMode:h}=(0,T.I)();if(!n)return a.createElement(a.Fragment,null,a.createElement("blockquote",null,"No examples have been written for this node yet. You can add some ",a.createElement("a",{href:`${u.i}/${c}`,target:"_blank"},"here")),a.createElement("br",null)," ",a.createElement("br",null));const _=JSON.parse(n).rfInstance,O="20em";return a.createElement("div",null,a.createElement(l.Z,null,a.createElement(r.Z,{value:"app",label:"App",default:!0},a.createElement(i.tV,null,a.createElement("div",{style:{height:O}},a.createElement(i.x$,{nodes:_.nodes,nodeTypes:f,edges:_.edges,fitView:!0,proOptions:{hideAttribution:!0}},a.createElement(o.a,{style:{backgroundColor:"light"===h?"rgba(0, 0, 0, 0.1)":"rgba(255, 255, 255, 0.1)",height:80,width:150},nodeColor:"light"===h?"rgba(0, 0, 0, 0.25)":"rgba(255, 255, 255, 0.25)",maskColor:"light"===h?"rgba(0, 0, 0, 0.05)":"rgba(255, 255, 255, 0.05)",zoomable:!0,pannable:!0}),a.createElement(d.A,null))))),a.createElement(r.Z,{value:"output",label:"Output"},a.createElement("div",{style:{minHeight:O}},a.createElement(s.k,null,a.createElement(E.E,{label:"x",style:C}),a.createElement(E.E,{dependentAxis:!0,label:"y",style:C}),a.createElement(m.C,{style:{data:{fill:"#7B61FF"}},size:1,data:t})))),a.createElement(r.Z,{value:"spec",label:"App JSON spec"},a.createElement("div",{style:{minHeight:O}},a.createElement(p.L,{data:_})))))}},89418:(e,n,t)=>{t.d(n,{Z:()=>r});var a=t(67294),l=t(25365);function r(e){let{children:n,index:t,folderPath:r}=e;const i=["notes.md","hardware.md","media.md"],o=["Theory and technical notes","Parts list and drivers","Media"][t],d="https://github.com/flojoy-io/docs/tree/main/docs/"+r+i[t],c="string"==typeof n&&n.includes("Driver doc :");return a.createElement(a.Fragment,null,a.createElement("br",null),a.createElement("details",null,a.createElement("summary",null,a.createElement("span",{style:{display:"inline-block",cursor:"pointer"}},a.createElement("h4",null,o))),c?null:""!==n?a.createElement(l.D,null,n):a.createElement(l.D,null,["No theory or technical notes have been contributed for this node yet.","This node does not require any peripheral hardware to operate. Please see INSTRUMENTS for nodes that interact with the physical world through connected hardware.","No supporting screenshots, photos, or videos have been added to the media.md file for this node."][t]),a.createElement("br",null),a.createElement("small",null,a.createElement("i",null,a.createElement("a",{href:d},"Edit ",i[t]," on GitHub")))),a.createElement("hr",null))}},57685:(e,n,t)=>{t.d(n,{Z:()=>c});var a=t(67294),l=t(5673),r=t(70266),i=t(7284),o=t(85012),d=t(92949);function c(e){let{children:n}=e;const{colorMode:t}=(0,d.I)();if(""===n.trim())return a.createElement(a.Fragment,null,a.createElement("blockquote",null,"This function does not have a docstring description yet."),a.createElement("br",null)," ",a.createElement("br",null));const r=n;return a.createElement(a.Fragment,null,a.createElement(l.Z,{language:"yaml",style:"dark"===t?i.Z:o.Z},r),a.createElement("br",null))}l.Z.registerLanguage("yaml",r.Z)},47062:(e,n,t)=>{t.d(n,{Z:()=>r});var a=t(67294),l=t(74160);function r(e){let{children:n}=e;if(""===n.trim())return a.createElement("blockquote",null,"This node does not currently have any input parameters.");const t=l.ZP.parse(n);return a.createElement("div",null,a.createElement("h3",null,"Input parameters"),Object.keys(t).map((e=>a.createElement(a.Fragment,null,a.createElement("details",null,a.createElement("summary",{key:e},a.createElement("code",null,e)),a.createElement("ul",null,Object.keys(t[e]).map((n=>a.createElement("li",{key:n},n," : ",JSON.stringify(t[e][n],void 0,4))))))))))}},79267:(e,n,t)=>{t.d(n,{Z:()=>i});var a=t(67294),l=t(60614),r=t(49188);function i(e){let{GLink:n,children:t}=e,i=t;if(i.includes('"""')){let e=i.split('"""')[0],n=i.split('"""')[2];i=e.trimEnd()+n.trimStart().replace("\n\n","\n")}return a.createElement("div",null,a.createElement("div",{style:{display:"flex",gap:"5px",justifyContent:"flex-start",alignItems:"center"}},a.createElement("h3",{style:{marginBottom:0}},"Python code"),a.createElement("a",{href:`${r.i}/${n}`,target:"_blank",rel:"noopener noreferrer",class:"navbar__item navbar__link header-github-link","aria-label":"GitHub repository",style:{padding:"5px"}},"Github",a.createElement("svg",{width:"13.5",height:"13.5","aria-hidden":"true",viewBox:"0 0 24 24",class:"iconExternalLink_node_modules-@docusaurus-theme-classic-lib-theme-Icon-ExternalLink-styles-module"},a.createElement("path",{fill:"currentColor",d:"M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"})))),a.createElement("details",{open:!0},a.createElement(l.Z,{className:"language-python"},i)),a.createElement("br",null))}},91906:(e,n,t)=>{t.d(n,{Z:()=>l});var a=t(67294);function l(){return a.createElement(a.Fragment,null,a.createElement("br",null),a.createElement("br",null),a.createElement("hr",null),a.createElement("br",null),a.createElement("br",null))}},49188:(e,n,t)=>{t.d(n,{i:()=>l,j:()=>a});const a={windows:"/getting-started/install/?platform=windows",mac:"/getting-started/install/?platform=unix"},l="https://github.com/flojoy-io/nodes/tree/main"},49664:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>g,contentTitle:()=>b,default:()=>N,frontMatter:()=>O,metadata:()=>y,toc:()=>I});var a=t(87462),l=(t(67294),t(3905)),r=t(57685),i=t(79267),o=t(47062),d=t(62605),c=t(91906),s=t(89418);const E="Performs  object detection on the input `DataContainer` class, specifically for the 'image' type,\n    represented by the RGB(A) channels.\n\n    Args:\n        dc_inputs (list[DataContainer]): List of DataContainer objects containing image channels.\n        params (dict): Additional parameters for object detection (not used in this function).\n\n    Returns:\n        DataContainer: A `DataContainer` class of type 'image' representing the output image with object detection results.\n\n    Raises:\n        Exception: If an error occurs during object detection.\n    ",m='import traceback\nfrom flojoy import flojoy, DataContainer\nimport numpy as np\n\nfrom utils.object_detection.object_detection import detect_object\n\n\n@flojoy\ndef OBJECT_DETECTION(dc_inputs: list[DataContainer], params: dict) -> DataContainer:\n    \n    dc_input: DataContainer = dc_inputs[0]\n    if dc_input.type != "image":\n        raise ValueError(\n            f"unsupported DataContainer type passed to OBJECT_DETECTION node: \'{dc_input.type}\'"\n        )\n    r = dc_input.r\n    g = dc_input.g\n    b = dc_input.b\n    a = dc_input.a\n\n    if a is not None:\n        nparr = np.stack((r, g, b, a), axis=2)\n    else:\n        nparr = np.stack((r, g, b), axis=2)\n    try:\n        img_array = detect_object(nparr)\n        red_channel = img_array[:, :, 0]\n        green_channel = img_array[:, :, 1]\n        blue_channel = img_array[:, :, 2]\n        if img_array.shape[2] == 4:\n            alpha_channel = img_array[:, :, 3]\n        else:\n            alpha_channel = None\n        return DataContainer(\n            type="image",\n            r=red_channel,\n            g=green_channel,\n            b=blue_channel,\n            a=alpha_channel,\n        )\n\n    except Exception:\n        print(traceback.format_exc())\n        raise\n',p="";var u=t(30164);const T='{\n    "rfInstance": {\n        "nodes": [\n            {\n                "width": 210,\n                "height": 130,\n                "id": "END-5e6d94ed-1f79-4c57-8b2f-753a22405f55",\n                "type": "TERMINATOR",\n                "data": {\n                    "id": "END-5e6d94ed-1f79-4c57-8b2f-753a22405f55",\n                    "label": "Terminate",\n                    "func": "END",\n                    "type": "TERMINATOR",\n                    "ctrls": {},\n                    "selected": false\n                },\n                "position": {\n                    "x": 1002.9112708314901,\n                    "y": 193.09986313255396\n                },\n                "selected": false,\n                "positionAbsolute": {\n                    "x": 1002.9112708314901,\n                    "y": 193.09986313255396\n                },\n                "dragging": true\n            },\n            {\n                "width": 210,\n                "height": 130,\n                "id": "OBJECT_DETECTION-95ba5f02-5971-4499-85d5-9d3d0427f115",\n                "type": "AI_OBJECT_DETECTION",\n                "data": {\n                    "id": "OBJECT_DETECTION-95ba5f02-5971-4499-85d5-9d3d0427f115",\n                    "label": "OBJECT DETECTION",\n                    "func": "OBJECT_DETECTION",\n                    "type": "AI_OBJECT_DETECTION",\n                    "ctrls": {},\n                    "pip_dependencies": [\n                        {\n                            "name": "opencv-python-headless",\n                            "v": "4.7.0.72"\n                        }\n                    ],\n                    "selected": false\n                },\n                "position": {\n                    "x": 592.0431664557512,\n                    "y": 194.4231797041855\n                },\n                "selected": false,\n                "positionAbsolute": {\n                    "x": 592.0431664557512,\n                    "y": 194.4231797041855\n                },\n                "dragging": true\n            },\n            {\n                "width": 150,\n                "height": 150,\n                "id": "LOCAL_FILE-94057446-4687-4613-9170-0accb0759dd9",\n                "type": "LOCAL_FILE_SYSTEM",\n                "data": {\n                    "id": "LOCAL_FILE-94057446-4687-4613-9170-0accb0759dd9",\n                    "label": "LOCAL FILE",\n                    "func": "LOCAL_FILE",\n                    "type": "LOCAL_FILE_SYSTEM",\n                    "ctrls": {\n                        "file_type": {\n                            "functionName": "LOCAL_FILE",\n                            "param": "file_type",\n                            "value": "image"\n                        },\n                        "path": {\n                            "functionName": "LOCAL_FILE",\n                            "param": "path",\n                            "value": ""\n                        }\n                    },\n                    "selected": false\n                },\n                "position": {\n                    "x": 202.04316645575113,\n                    "y": 174.42317970418543\n                },\n                "selected": false,\n                "positionAbsolute": {\n                    "x": 202.04316645575113,\n                    "y": 174.42317970418543\n                },\n                "dragging": true\n            }\n        ],\n        "edges": [\n            {\n                "source": "LOCAL_FILE-94057446-4687-4613-9170-0accb0759dd9",\n                "sourceHandle": "main",\n                "target": "OBJECT_DETECTION-95ba5f02-5971-4499-85d5-9d3d0427f115",\n                "targetHandle": "OBJECT_DETECTION",\n                "id": "reactflow__edge-LOCAL_FILE-94057446-4687-4613-9170-0accb0759dd9main-OBJECT_DETECTION-95ba5f02-5971-4499-85d5-9d3d0427f115OBJECT_DETECTION"\n            },\n            {\n                "source": "OBJECT_DETECTION-95ba5f02-5971-4499-85d5-9d3d0427f115",\n                "sourceHandle": "main",\n                "target": "END-5e6d94ed-1f79-4c57-8b2f-753a22405f55",\n                "targetHandle": "END",\n                "id": "reactflow__edge-OBJECT_DETECTION-95ba5f02-5971-4499-85d5-9d3d0427f115main-END-5e6d94ed-1f79-4c57-8b2f-753a22405f55END"\n            }\n        ],\n        "viewport": {\n            "x": 197.02420568593084,\n            "y": 51.49831064898197,\n            "zoom": 0.9164609015292902\n        }\n    },\n    "ctrlsManifest": [\n        {\n            "type": "output",\n            "name": "Plot",\n            "minWidth": 2,\n            "minHeight": 3,\n            "id": "ctrl-d81b57c0-dda4-4160-894c-8307b5df7ef7",\n            "hidden": false,\n            "param": "OBJECT_DETECTION-a9866d79-0bc0-45d7-a2a4-6825b7a012bd",\n            "val": 0,\n            "layout": {\n                "w": 4,\n                "h": 4,\n                "x": 2,\n                "y": 0,\n                "i": "ctrl-d81b57c0-dda4-4160-894c-8307b5df7ef7",\n                "minW": 2,\n                "minH": 3,\n                "moved": false,\n                "static": true\n            }\n        },\n        {\n            "type": "input",\n            "name": "Text Input",\n            "minWidth": 1,\n            "minHeight": 1,\n            "id": "ctrl-e813ad6f-6717-4242-b705-2ef72861fe45",\n            "hidden": false,\n            "param": {\n                "id": "LOCAL_FILE_LOCALFILE_path",\n                "functionName": "LOCAL_FILE",\n                "param": "path",\n                "nodeId": "LOCAL_FILE-b6953411-4f5e-4f22-aaba-bdc923e56b86",\n                "inputId": "ctrl-e813ad6f-6717-4242-b705-2ef72861fe45"\n            },\n            "val": 0,\n            "layout": {\n                "w": 2,\n                "h": 2,\n                "x": 0,\n                "y": 0,\n                "i": "ctrl-e813ad6f-6717-4242-b705-2ef72861fe45",\n                "minW": 1,\n                "minH": 1,\n                "moved": false,\n                "static": true\n            }\n        }\n    ]\n}',f="",C="",h="",_="",O={},b=void 0,y={unversionedId:"nodes/AI_ML/OBJECT_DETECTION/OBJECT_DETECTION",id:"nodes/AI_ML/OBJECT_DETECTION/OBJECT_DETECTION",title:"OBJECT_DETECTION",description:"[//]: # (Custom component imports)",source:"@site/docs/nodes/AI_ML/OBJECT_DETECTION/OBJECT_DETECTION.md",sourceDirName:"nodes/AI_ML/OBJECT_DETECTION",slug:"/nodes/AI_ML/OBJECT_DETECTION/",permalink:"/nodes/AI_ML/OBJECT_DETECTION/",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"main",previous:{title:"LOADER",permalink:"/nodes/LOADERS/CLOUD_DATABASE/LOADER/"},next:{title:"SKLEARNIMAGE",permalink:"/nodes/GENERATORS/SAMPLE_IMAGES/SKLEARNIMAGE/"}},g={},I=[{value:"Examples",id:"examples",level:2},{value:"Appendix",id:"appendix",level:2}],L={toc:I},D="wrapper";function N(e){let{components:n,...t}=e;return(0,l.kt)(D,(0,a.Z)({},L,t,{components:n,mdxType:"MDXLayout"}),(0,l.kt)(r.Z,{mdxType:"DocString"},E),(0,l.kt)(i.Z,{GLink:"AI_ML/OBJECT_DETECTION/OBJECT_DETECTION.py",mdxType:"PythonCode"},m),(0,l.kt)(o.Z,{mdxType:"Parameters"},p),(0,l.kt)(c.Z,{mdxType:"SectionBreak"}),(0,l.kt)("h2",{id:"examples"},"Examples"),(0,l.kt)(d.Z,{data:f,nodeLabel:"OBJECT_DETECTION",mdxType:"AppDisplay"},T),(0,l.kt)(u.default,{mdxType:"Example1"}),(0,l.kt)(c.Z,{mdxType:"SectionBreak"}),(0,l.kt)("h2",{id:"appendix"},"Appendix"),(0,l.kt)(s.Z,{index:0,folderPath:"nodes/AI_ML/OBJECT_DETECTION/appendix/",mdxType:"AppendixSection"},C),(0,l.kt)(s.Z,{index:1,folderPath:"nodes/AI_ML/OBJECT_DETECTION/appendix/",mdxType:"AppendixSection"},h),(0,l.kt)(s.Z,{index:2,folderPath:"nodes/AI_ML/OBJECT_DETECTION/appendix/",mdxType:"AppendixSection"},_))}N.isMDXComponent=!0},30164:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>m,frontMatter:()=>r,metadata:()=>o,toc:()=>c});var a=t(87462),l=(t(67294),t(3905));const r={},i=void 0,o={unversionedId:"nodes/AI_ML/OBJECT_DETECTION/examples/EX1/example",id:"nodes/AI_ML/OBJECT_DETECTION/examples/EX1/example",title:"example",description:"ITS AN OBJECT DETECTION APP WHICH USES OBJECT DETECTION NODE TO DETECT OBJECT.",source:"@site/docs/nodes/AI_ML/OBJECT_DETECTION/examples/EX1/example.md",sourceDirName:"nodes/AI_ML/OBJECT_DETECTION/examples/EX1",slug:"/nodes/AI_ML/OBJECT_DETECTION/examples/EX1/example",permalink:"/nodes/AI_ML/OBJECT_DETECTION/examples/EX1/example",draft:!1,tags:[],version:"current",frontMatter:{}},d={},c=[],s={toc:c},E="wrapper";function m(e){let{components:n,...t}=e;return(0,l.kt)(E,(0,a.Z)({},s,t,{components:n,mdxType:"MDXLayout"}),(0,l.kt)("p",null,"ITS AN OBJECT DETECTION APP WHICH USES OBJECT DETECTION NODE TO DETECT OBJECT."))}m.isMDXComponent=!0}}]);